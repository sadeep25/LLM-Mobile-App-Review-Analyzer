{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #installing the necessary libraries\n",
    "!pip install trl \n",
    "!pip install transformers==4.39.3\n",
    "!pip install git+https://github.com/huggingface/peft.git\n",
    "!pip install datasets==2.15.0\n",
    "!pip install bitsandbytes\n",
    "!pip install einops \n",
    "!pip install wandb\n",
    "!pip install accelerate \n",
    "!pip install numba\n",
    "!pip install ipywidgets\n",
    "!pip install seaborn\n",
    "!pip install tqdm\n",
    "!pip install scikit-learn\n",
    "\n",
    "!git config --global user.email \"email@gmail.com\"\n",
    "!git config --global user.name \"username\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../Common\")\n",
    "import ModelHelper as model_helper\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "HUGGINGFACE_TOKEN=\"HUGGINGFACE_TOKEN\"\n",
    "SECRET_WAND_TOKEN=\"SECRET_WAND_TOKEN\"\n",
    "debug = False\n",
    "inferrence_only = False\n",
    "input_path_training=\"../Data/training.json\"\n",
    "input_path_validataion=\"../Data/validation.json\"\n",
    "\n",
    "#model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#infernce\n",
    "temperature_value = 1 \n",
    "top_p_value = 1\n",
    "max_length_value_inference = 30\n",
    "iterations = 3\n",
    "\n",
    "#training\n",
    "max_length_value_training = 800\n",
    "number_of_reviews = 10000\n",
    "number_of_epochs = 1\n",
    "is_Explanation = False\n",
    "\n",
    "if is_Explanation:\n",
    "    max_length_value_inference = 80\n",
    "\n",
    "new_model = \"\"\n",
    "if model_name == \"mistralai/Mistral-7B-Instruct-v0.1\":\n",
    "    new_model = f\"mistral-7b-mobile-app-review-analyzer-{number_of_reviews}-reviews-{number_of_epochs}-epochs-Explaination-{is_Explanation}\"     \n",
    "elif model_name == \"meta-llama/Llama-2-7b-chat-hf\":\n",
    "    new_model = f\"llama-7b-mobile-app-review-analyzer-{number_of_reviews}-reviews-{number_of_epochs}-epochs-Explaination-{is_Explanation}\"\n",
    "else:\n",
    "    print(\"Please provide a valid model name\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Fintuned model name : {new_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "if not inferrence_only:\n",
    "    model_helper.train_model(input_path_training, number_of_reviews, is_Explanation, debug, model_name, new_model, number_of_epochs, max_length_value_training, HUGGINGFACE_TOKEN, SECRET_WAND_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not inferrence_only:\n",
    "    model_helper.push_model(HUGGINGFACE_TOKEN, model_name, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference\n",
    "model_helper.inference_model(iterations,HUGGINGFACE_TOKEN, new_model, debug, temperature_value, top_p_value, input_path_validataion, is_Explanation, max_length_value_inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
